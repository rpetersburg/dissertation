\chapter{Conclusions}\label{chapter:conclusion}

In summary, this thesis presented new research to the field of radial-velocity spectroscopy instrumentation in support of various aspects of EXPRES, including its fiber architecture, wavelength calibration sources, spectral extraction, and data analysis. In Chapter \ref{chapter:modal-noise}, I found that quasi-chaotic fiber agitation, through the use of dual rotating arms, would optimally mitigate modal noise within the fibers leading to the spectrograph, decreasing laser frequency comb wavelength calibration radial-velocity scatter from 32.8\cms to 6.6\cms for EXPRES. In Chapter \ref{chapter:astro-comb}, I demonstrated the viability of aluminum nitride as a candidate for future astro-comb development, due to its high transparency and frequency conversation efficiency across a wider bandpass than that provided by the EXPRES laser frequency comb. In Chapter \ref{chapter:pipeline}, I introduced the default EXPRES flat-relative optimal extraction pipeline, yielding single measurement precision of less than 30\cms for observations with a signal-to-noise greater than 250 at 550~\si{\nano\meter} and kicking off the next-generation of radial-velocity measurement. Finally, in Chapter \ref{chapter:pipeline2}, I described further improvements made to the EXPRES pipeline---flat-relative spectro-perfectionism and \textit{B}-spline regression stellar templating---that provide radial-velocity results similar to those from the optimal extraction while also enabling greater diagnostic capability with our data.

In lieu of further summary of the conclusions already presented in the individual chapters of this thesis, I have instead organized these final conclusions into a set of lessons learned (Chapter \ref{conclusion:lessons}), a compilation of future work that could build off of this research (Chapter \ref{conclusion:future}, and my final thoughts (Chapter \ref{conclusion:final}). As a result of completing all of this research and synthesizing it into this massive document, I have been granted an extensive range of experiences that have shaped my perception of radial-velocity spectroscopy. I hope that by compiling just some of these ideas here, they can more easily be passed to those who wish to continue improving instrumentation and data extraction within this exciting field.

\section{Lessons Learned} \label{conclusion:lessons}

\textbf{Optical fiber break protection is best achieved with flexible metal sheaths}, followed closely by soft rubber jackets. While testing a variety of optical fibers during the modal noise study of Chapter \ref{chapter:modal-noise}, I found that fibers jacketed with hard plastic or rubber were much more likely to break than those with metal sheaths or soft rubber. This is likely due to a certain ``breaking point'' of the hard jacket, where once it is bent tighter than a certain radius, the jacket kinks and snaps the fiber. With softer jackets, the allowed radii of curvature are much smaller (potentially leading to worse transmission, especially in bluer wavelengths), but at least the fiber won't be broken.

\textbf{Building an in-house electro-optic modulation comb requires a high-energy pulse-width measuring device.} The greatest problem we faced while prototyping the elctro-optic modulation comb in Chapter \ref{chapter:astro-comb} was a lack of understanding the pulse width at each stage of the device. The pulse-width measurement made for Figure \ref{fig:eom-pulse} was taken with a FROG, but involved burning multiple neutral density filters due to the very high peak energy of the pulse. Investment in a more robust device early on would have certainly made this process simpler, especially since the ultimate challenge of our comb was likely insufficient pulse compression.

\textbf{Finding and fixing major outliers is more critical than incrementally tweaking algorithms.} I'll explain this using an example. Recently, in the midst of trying to improve our wavelength calibration algorithm by a few \si{\centi\meter\per\second}, we found that radial velocities from a single night were off from the rest by multiple \si{\meter\per\second}! This was caused by a failure in our interpolation scheme (a cubic polynomial fit) when less than three sets of LFCs were taken throughout the night. We fixed it by instead implementing a linear interpolation scheme with nearest neighbors weighting, decreasing velocity scatter by $\sim$1~\si{\meter\per\second} for a few target stars. Therefore, our problems were better solved by focusing on avoiding a big issue rather than tweaking small default parameters.

\textbf{Centralizing data analysis code enables quicker repairs and validation.} Data extraction and analysis for a high-resolution spectrograph is a massive enterprise. It would have not been possible to conduct much of this work by passing data from person to person in order to individually run reduction, extraction, wavelength calibration, etc. Using tools like git and features of GitHub like issue-tracking and release tags has been a life-saver, enabling better documentation and collaboration when things are going wrong.

\section{Future Work} \label{conclusion:future}

\textbf{Further electro-optic modulation comb development.} As explained in Chapter \ref{chapter:astro-comb}, \citet{obrzud_visible_2019} used a similar electro-optic comb design to our own with some spectacular results. I believe we were on the right track with our design, but simply did not implement enough broadening before the aluminum nitride waveguide (again, thinking big issues rather than small tweaks). Other possible areas of exploration include implementing a chirped fiber bragg grating for better dispersion control, using longer aluminum nitride waveguides, or even attempting to couple micro-rings with the electro-optic modulation comb.

\textbf{Charge Transfer Inefficiency.} One element completely missing from the EXPRES pipeline is any correction for charge transfer inefficiency \citep{goudfrooij_empirical_2006, bouchy_charge_2009, blake_impact_2017}. The mechanisms for simulating it are fairly well-known, but there has yet to be a simple pixel-wise correction model that can be applied to the reduced data. Although this effect is likely minimized on EXPRES due to consistency in signal-to-noise \citep{blackman_performance_2020}, it may play an important role in laser frequency comb calibration due to the high contrast of individual comb lines.

\textbf{Telluric modeling and expanding the radial-velocity window.} I find Figure \ref{fig:chunk-vels} rather telling about where to focus radial-velocity efforts: improve telluric modeling from 550--830~\si{\nano\meter} (since the scatter here is well above 100\ms) and fix systematic problems in wavelength calibration in the region from 400~\si{\nano\meter} to 500~\si{\nano\meter}. There is so much high fidelity data in the bluer regions of the detector and it would be a shame for us to continue not using it (another instance of thinking big!). As a first step towards better telluric modeling, I would recommend applying the \textit{B}-spline regression method of Chapter \ref{chapter:pipeline2} to the empirical analysis of B-stars from SELENITE, which currently uses simple order-wise interpolation methods. Naturally, this should be combined with continued improvements in suppressing stellar activity signals, but it seems to me that tellurics are underappreciated in our analyses.

\textbf{Spectro-perfectionism sampling study.} The biggest gain from using spectro-pefectionism over optimal extraction is its ability to sample the detector at an arbitrary rate. I would recommend implementing flat-relative spectroperfectionism such that it is normalized regardless of the sampling rate and then conducting a study to see how matching sampling to instrument dispersion may improve the fidelity of extracted spectra. In particular, I would be curious to see if overlapping orders are better aligned than when using the flat-relative optimal extraction.

\textbf{Complete spectrograph forward modeling.} According to the most recent NASA Exoplanet Exploration Analysis Program Group meeting, a high priority within the community is generating extraction code that is able to completely forward model a radial velocity into the two-dimensional pixel space of a reduced detector exposure. This would eliminate the need to move step-to-step between extraction, wavelength calibration, barycentric correction, telluric modeling, etc. where uncertainty has to be modeled and propagated through each step. Naturally, spectro-perfectionism and stellar templating may play a role in such analysis, and it will be fascinating regardless to see if such a major shift in extraction techniques occurs.

\section{Final thoughts} \label{conclusion:final}

The goal of discovering exoplanets that impart less than a 10~\si{\centi\meter\per\second} stellar radial velocity is certainly a lofty one. As demonstrated in this thesis, the EXtreme PREcision Spectrograph is definitely living up to its expectations of being a next-generation radial-velocity instrument. Getting to this point, however, required the expertise of multiple generations of spectrographs being passed down through their future iterations. This is how we've moved from boxcar extraction to optimal extraction to spectro-perfectionism and from iodine cells to thorium-argon lamps to mode-locked laser frequency combs to on-chip micro-ring resonators. We are in an exciting time of high-precision spectroscopy, finally leveraging the radial-velocity technique to detect Earth-like exoplanets and possibly discovering if there really is life somewhere out there.